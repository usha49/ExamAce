Context Free Languages (CFL) 
 
Language Recognizer 
A device that accepts valid strings. The FA are formalized types of language recognizer. 
Language Generator: 
Context free grammars are language generators, which are based on a more complete 
understanding of the structure of the strings belonging to the language. 
Regular expression can be also viewed as language generator. E. g.  a(a* b*) b . In verbal form  
 First output an a then  
 Either output  a number of  a's or output number of b's 
 Finally output a b. 
Using context free grammar same language can be generated . For a(a* b*) b  
Let  S   be a new symbol interpreted as  "a string in the language"  
M be a symbol standing for middle part. 
Then ,we can express  
S  aMb 
Here, M can be either string of a's or string of b's .  
So, M  A and M B  
strings of a's can be empty string so A e  or  it may consist of a leading a followed by a string 
of a's  
A aA 
Similarly  
B e 
B bB.  
 
For Example : To generate a string aaab. 
S  aMb 
   aAb   
 
 (MA) 
   aaAb  
 
 (AaA ) 
    aaaAb 
 
 (AaA ) 
  aaab    
 
(Ae ) 
 
The Context free grammar is a language generator that operates like the one above ,with some 
such a set of rules.  
 
 
 
 
 
ioenotes.edu.np

Why it is called Context free?  
Consider S  aaAb  ,  
 
    it is  surrounded by aa and b , its called context of A, Now the rule A aA 
says that we can replace A by the string aA no matter what the surrounding 
strings are  i. e.  independent of the context of A. 
 
 
The following is a example of a context-free grammar, called G , which describes a fragment of 
the English language. 
(SENTENCE)  (NOUN-PHRASE)(VERB-PHRASE) 
(NOUN-PHRASE)  (CMPLX-NOUN) / (CMPLX-NOUN)(PREP-PHRASE) 
(VERB-PHRASE) (CMPLX-VERB)  /(CMPLX-VERB) (PREP-PHRASE) 
(PREP-PHRASE) (PREP) (CMPLX-NOUN) 
(CMPLX-NOUN)   (ARTICLE) (NOUN) 
(CMPLX-VERB) (VERB) /  (VERB)(NOUN-PHRASE) 
(ARTICLE)  a/ the 
(NOUN)  boy/girl/flower 
(VERB)  touches/likes/sees 
(PREP)   with  
 
 
Grammar G has 10 variables (the capitalized grammatical terms written inside brackets); 27 
terminals (the standard English alphabet plus a space character); and 18 rules. Strings in L(G) 
include 
 
a boy sees 
the boy sees a flower 
a girl with a flower likes the boy 
Each of these strings has a derivation in grammar G. The following is a derivation of the first 
string on this list. 
 
(SENTENCE) (NOUN-PHRASE) (VERB-PHRASE) 
 (CMPLX-NOUN)(VERB-PHRASE) 
 (ARTICLE) (NOUN) (VERB-PHRASE) 
 a (NOUN)(VERB-PHRASE) 
 a boy (VERB-PHRASE) 
 a boy (CMPLX-VERB) 
 a boy (VERB) 
 a boy sees 
 
 
 
ioenotes.edu.np

Formal Definition 
A Context free grammar G is quadruple (V, ∑, R, S) , where  
 V is an alphabet  (finite set of variables) 
 ∑ the set of terminals (is a subset of V) 
 R the set of rules (is finite subset of V-∑ x V*) 
 S the start symbol (is an element of V- ∑) 
Here the member of V - ∑ is called non terminals 
 
Derivation of string from CFG 
A derivation of a string w in a given grammar G is a sequence of substitutions starting with the 
start symbol and resulting in w.  
If u, v, and w are strings of variables and terminals, and A  w is a rule of the grammar, we say 
that uAv yields uwv, written uAv   uwv. Say that u derives v, written u * v, if u v  or if a 
sequence ul, u2, . ., uk exists for k ≥ 0 and   
u  u1 u2  .. …….  uk  v. 
 
e.g. 
A0A1 
A  B 
B# 
 
A 0A100A11  000A111  000B111  000#111 is a derivation of the string 000#111 in 
the grammar defined above.  
The symbol "" reads "yields".  We say u derives v and write u  *  v  if there is a derivation 
(for some k ≥ 0): u  u1 u2 ……… uk   v 
When the grammar to which we refer is obvious, we write A  w and u  v instead of A G   
w and u G v. 
We call any sequence of the form 
W0 G WI G ... GWn   is called a derivation in G of Wn from W0.    Here Wo,···, Wn may be 
any strings in V*, and n, the length of the derivation, may be any natural number, including zero. 
We also say that the derivation has n steps. 
 
Examples 
Design a context-free grammar (CFG) for the language {anbn :  n ≥ O}. 
Solution 
Let required  CFG G = (V,∑, R, S)  where 
 
V = {S, a, b},  
∑ = {a, b}, and R consists of the rules  
S  aSb   (rule 1) and 
 S  e. (rule 2) 
 
Derivation example 
A possible derivation is  
S => aSb  ( apply rule  1) 
ioenotes.edu.np

    => aaSbb ( apply rule  1) 
    => aabb ( apply rule  2) 
 
Example 2 
Design a CFG for the language consists of all strings over the alphabet {(,), +, *, id} that 
represent syntactically correct arithmetic expressions involving + and *. id stands for any 
identifier, that is to say, variable name .Examples of such strings are id and id * (id * id + id), but 
not *id + ( or + * id. 
Solution 
Let G = (V,∑, R, E) where V, ∑, and R are as follows. 
V = {+,*, ( , ) , id, T,F , E}, 
∑= {+, *, (, ), id}, 
 
R = { 
         E  E +T,  
 
 
(R1) 
         E T,  
 
 
(R2) 
        TT*F,  
 
 
(R3) 
        TF, 
 
 
 
(R4) 
        F  (E),  
 
 
(R5) 
        F  id }.  
 
 
(R6) 
The symbols  E, T, and F are abbreviations for expression, term, and factor, respectively. 
The grammar G generates the string (id * id + id) * (id + id) by the following derivation. 
 
E T  
 
 
by  R2 
   T*F  
 
 
by  R3 
   T* (E)  
 
 
by R5 
  T* (E +T)  
 
 by R1 
 T * (T + T)  
 
by R2 
 T* (F + T)   
 
by R4 
 T* (id + T)   
 
by R6 
T* (id + F)   
 
by R4 
T * (id + id)  
 
by R6 
F * (id + id)  
 
by R4 
 (E) * (id + id)  
 
by R5 
 (E + T) * (id + id)   
by  R1 
 (E+F)*(id+ id)  
 
by R4 
 (E + id) * (id + id)   
by R6 
 (T + id) * (id + id)   
by R2 
 (T * F + id) * (id + id)  
 by R3 
 (F * F + id) * (id + id)  
by R4 
 (F * id + id) * (id + id) 
by R6 
 (id * id + id) * (id + id) 
 by R6 
 
 
 
ioenotes.edu.np

Example 3 
Design a CFG that generates all strings of properly balanced left and right parentheses: every left 
parenthesis can be paired with a unique subsequent right parenthesis, and every right parenthesis 
can be paired with a unique preceding left parenthesis. 
 
Solution 
Let required grammar G = (V, ∑, R, S), where 
V = { S, ( , ) }, 
∑= { ( , ) }, 
R = { 
Se, 
S  SS, 
S  (S)  
       }. 
 
To generate the string   ()(()) 
 one possible derivation is 
S  SS  
S(S) 
S((S)) 
  S(())  
 ()(()) 
 
or  we can generate by following  way. 
 
S  SS  
 (S)S 
  ()S  
 ()(S)  
()(()) 
 
Thus the same string may have several derivations in a context-free grammar; 
 
Leftmost derivation 
In leftmost derivation, when a step of a derivation can be a part of a leftmost derivation: the 
leftmost non-terminal must be replaced. Derivation of a string w in a grammar G is a leftmost 
derivation if at every step the leftmost remaining variable is the one replaced. 
 
We write  
 if and only if x = wAβ, y = wαβ, where w є ∑ *, 0:,,8 E V', A є V*-I;, and 
A  0: 
is a rule of G. Thus, if Xl * X2 * ... * Xn is a leftmost derivation, then in 
fact Xl i X2 i ... i Xn- 
 
Rightmost derivation 
 
ioenotes.edu.np

 
 
 
 
Theorem  
Let G = (V,∑, R, S) be a context-free grammar, and let A є V - ∑ , and w є ∑*. Then the 
following statements are equivalent: 
(a) A * w. 
 
(b) There is a parse tree with root A and yield w. 
(c) There is a leftmost derivation A  
w. 
 
(d) There is a rightmost derivation A 
w. 
 
 
 
Application of CFG 
 An important application of context-free grammars occurs in the specification and 
compilation of programming languages.  
 Most compilers and interpreters contain a component called a parser that extracts the 
meaning of a program prior to generating the compiled code or performing the 
interpreted execution. 
 
 
 
 
ioenotes.edu.np

Parse/ derivation Trees 
Parsing 
A compiler translates code written in a programming language into another form, usually one 
more suitable for execution. To do so the compiler extracts the meaning of the code to be 
compiled in a process called parsing.  “Parsing” a string is finding a derivation (or a derivation 
tree) for that string.  Parsing a string is like recognizing a string. The only realistic way to 
recognize a string of a context-free grammar is to parse it. 
 
A parse tree is a convenient way to represent a derivation of a particular string.  
A ‘derivation tree’ is an ordered tree which the  nodes are labeled with the left sides of 
productions and in which the children of a node represent its corresponding right sides. 
Formal Definition 
Let G = (V, ∑, R, S) be a CFG. An ordered tree is a derivation tree for G if it 
has the following properties: 
 The root of the derivation tree is S. 
 Each and every leaf in the tree has a label from ∑  {e}. 
 Each and every interior vertex (a vertex which is no a leaf) has a label from V. 
 If a vertex has label A є V, and its children are labeled (from left to right) a1 , a2 , ….  an, 
then R must contain a production of the form 
A a1,  a2, …..  an  
  A leaf labeled l has no siblings, that is, a vertex with a child labeled e can have no other 
children. 
 
For example, in the grammar 
A  0A1 
A  B 
B  # 
Derivation of the string 000#111 is given by the tree: 
 
 
 
 
Formally, for an arbitrary context-free grammar G = (V, ∑, R, S), we define its parse trees and 
their roots, leaves, and yields, as follows. 
1. This is a parse tree for each  a є ∑. The single node of this parse tree is both the root and 
a leaf. The yield of this parse tree is a. 
2. If Ae is a rule in R, then  
ioenotes.edu.np

 
 is a parse tree; its root is the node labeled A, its sole leaf is the node labeled e, and its yield is e. 
3.  If 
 
Are parse trees, where n ≥ 1, with roots labeled A1, . .. , An respectively, and with yields Y1, ... , 
Yn, and A  Al ... An is a rule in R, then 
 
is a parse tree. Its root is the new node labeled A, its leaves are the leaves of its constituent parse 
trees, and its yield is Y1... Yn. 
 
4. Nothing else is a parse tree. 
 
Example 
For example, if G is the context-free grammar that generates the language of balanced 
parentheses , then the string ()() can be derived from S by at least two distinct derivations, 
namely, 
         
S  S S  (S)S  ()S  () (S)  ()() 
and 
S SSS(S)  (S)(S)  (S()  () () 
 
However, these two derivations are in a sense "the same." The rules used are the same, and they 
are applied at the same places in the intermediate string. The only difference is in the order in 
which the rules are applied. 
 
ioenotes.edu.np

 
Fig: Parse tree for  ()() 
 
 
Ambiguity in CFG: 
Grammars such as G, with strings that have two or more distinct parse trees, are called 
ambiguous. 
If a grammar generates the same string in several different ways, we say that the string is derived 
ambiguously in that grammar. If a grammar generates some string ambiguously we say that the 
grammar is ambiguous. 
Formal Definition 
A string  w is derived ambiguously in context-free grammar G if it has two or more different 
leftmost derivations. Grammar G is ambiguous if it generates some string ambiguously. 
 
ioenotes.edu.np

 
 
 
ioenotes.edu.np

 
Inherently ambiguous. 
Sometimes when we have an ambiguous grammar we can find an unambiguous grammar that 
generates the same language. Some context-free languages, however, can be generated only by 
ambiguous grammars. Such languages are called inherently ambiguous. 
 
Ambiguity is a property of a grammar, and it is usually, but not always possible to find an 
equivalent unambiguous grammar. 
An “inherently ambiguous language” is a language for which no unambiguous grammar exists. 
 
 
Simplification of CFG 
 
Normal Forms 
Two kinds of normal forms viz.,  
 Chomsky Normal Form (CNF) and 
  Greibach Normal Form (GNF). 
 
Chomsky Nor mal Form (CNF) 
 
Any context-free language L without any  e -production is generated by a grammar is which 
productions are of the form A   BC or A  a, where 
A, B  є  V ( , and a є ∑ . 
NT  NT x NT or  
NT T 
 
NT : non terminal 
T : Terminal  
 
 
Procedure to find Equivalent Grammar in CNF 
ioenotes.edu.np

 
(i) Eliminate the unit productions, and l-productions if any, 
(ii) Eliminate the terminals on the right hand side of length two or more. 
(iii) Restrict the number of variables on the right hand side of productions to two. 
 
Example 
Let us consider the grammar G= (V, , R, S) where  
V= {S, A, B} 
 = {a, b},and the productions R  are : 
S  
bA / aB 
A 
bAA / aS / a 
B  
aBB / bS / b 
find an equivalent grammar in CNF 
First, the only productions already in proper form are A a and B b. 
There are no unit productions, so we may begin by replacing terminals on the right by variables, 
except in the case of the productions A a and B b. 
S  bA is replaced by S  Cb A and Cb b.  
Similarly, AaS is replaced by A  Ca S and C a  a and A  bAA is replaced by ACbAA; 
S aB is replaced by S Ca B; 
B  bS is replaced by B Cb S, and B  aBB is replaced by B Ca BB. 
 
In the next stage, the production A CbAA is replaced by A   CbD1 and 
D1   A A, and the production B CaBB is replaced by B  CaD2 and D2  BB 
The productions for the grammar in CNF are shown below. 
S CbA/CaB 
A CaS/  CbD /  a 
B  CbS/CaD2/ b 
D1   AA 
D2 BB 
Ca  a 
Cb b 
 
ioenotes.edu.np

 
Pushdown Automata(PDA) 
Consider the language L1 L1={ WCWR : W ∈ ∑ *   or  L2= { anbn :    n≥ 1 }, these languages are 
generated by CFG but can't be accepted by FA. So all CFG's  are not accepted by FA. here  we 
need to remember the strings before it goes to next part of the string and compare it with first 
half but FA can't do this because in FA don’t have capability of remember anything.  PDA  is 
essentially a FA with control of both an input tape and a stack to store what it has read. A stack is 
a FIFO. PDA can accept all CFGs. PDA have three things 
 input tape 
  Finite control 
 Stack  
 
Input Tape 
a 
b 
c 
b 
a 
 
 
 
 
 
 
 
 
 
Definition of PDA: 
A pushdown automata is a system  which is mathematically defined by sixtuple 
M= (K, ∑, Г ,∆ , S , F) 
where ,  
K: Finite set of states 
∑: is an alphabets (input symbols) 
Г : stack symbols 
S ∈ K ,initial state 
F K :set of final states 
∆ : transition relation is a finite subset of Kx(∑  {e} x Г * ) x (K x Г *) 
i.e  
Kx (∑  {e} x Г * )   (Kx Г *) 
Transition :  
if (p, a, β) , (q , γ)  ∈ ∆ , then  M whenever it is in state p with ' β ' at the top of stack may read ' γ' 
from the input tape ,replace ' β'  by  ' γ'  on the top of the stack and enter state q. such pair (p , a, 
β)  , (q, γ)  is called a transition of M.  
Push/pop 
Push : symbol input is to add to the top of stack . e.g  (p, u, e) , ( q, a) pushes a to the top of stack 
 
b 
c 
b 
a 
    Finite Control 
Stack top 
     Stack or pushdown store 
    Finite Control 
ioenotes.edu.np

Pop: symbol is to remove it from the top of the stack . e.g. (P, u, e) , (q , e) pops a. 
 
Configuration of  PDA 
Configuration of   a pushdown automaton is defined to be a member of K X ∑* x Г * . The first 
component is the state of the machine (K), the second is the portion of the input yet to be read 
(∑*) , and the third is the contents of the pushdown store, read top-down (Г *).  
For example, if the configuration were (q, W, abc), the ' a '  would be on the top of the stack and 
the 'c' on the bottom. If (p, x, α) and (q, y, β) are configurations of M, we say that (p, x, α) yields 
in one step (q, y, β) . Thus a configuration of the machine is a triple (q, string,  stack).  
 When pushing symbol x, the configuration changes from (q, a.w, ε.t) to (qi, w, x.t). 
 When popping symbol x, the configuration changes from(q, a.w, x.t) to (qi,w, t). 
 When we don’t wish the stack to change at all in a computation step, the machine moves 
from a configuration (q, a·w, ε·t) to (qi,w, ε.t). 
 Finally, on the occasion that we actually do wish to change the symbol c at the top of stack 
with symbol d, the configuration (q, a.w, c.t) changes to (qi,w, d.t). 
An execution starts with the configuration (q0, s, ε), i.e., the machine is in the start state, the input 
string s is on the tape, and the stack is empty. A successful execution is one which finishes in a 
configuration where s has been completely read, the final state of the machine is an accept state, 
and the stack is empty. 
 
PDA as a state diagram: 
 
 
Example 1 
Design a pushdown automaton M to accept the language L = {WcWR : w ∈ {a, b } *}.  
Solution :  According to given language , ababcbaba  ∈  L  but  abcab   є  L. Let  required PDA,   
M= (K, ∑, Г ,∆ , S , F) where  
K = {s , f} 
∑= {a, b, c} 
Г= {a, b} 
F = {f} and  
∆  is given by following five transitions 
1. ((s, a, e),(s, a) //push a 
2. ((s, b, e),(s, b))  //push b 
3. (( s, c, e), (f, e))  // change the state 
ioenotes.edu.np

4. ((f, a, a),(f, e))  // pop a on reading of input symbol a 
5. ((f, b, b),(f, e)) // pop b on reading of input symbol b 
 
State  diagram 
 
 
 
 
 
 
e.g Lets check for the string abbcbba  
 
State 
Unread input 
stack content 
Transition used 
s 
abbcbba 
e 
- 
s 
bbcbba 
a 
1 
s 
bcbba 
ba 
2 
s 
cbba 
bba 
2 
f 
bba 
bba 
3 
f 
ba 
ba 
5 
f 
a 
a 
5 
f 
e 
e 
4 
 
 Here when machine sees a 'c' in input string , it switches from state s to f without 
operating on its stack.  
 If the input symbol does not match the top stack symbol,  no further operation is 
possible 
 IF an automaton M reaches in configuration (f, e, e) , final state, end of input , empty 
stack , then the input was indeed of the form WcWR 
 
 
Example 2 
Design a PDA M that accept a language given by L= { anbn :    n ≥ 1 } . 
Solution 
Let required PDA,   M= (K, ∑, Г ,∆ , S , F) where  
K = {s , q, f} 
∑= {a,b} 
Г= {a} 
F = {f} and  
∆  is given by following five transitions 
1. ((s,a,e),(s,a) //push a 
2. ((s,a,a),(s,a) //push a 
3. ((s,b,a),(q,e))  //pop a, when first b is encountered and also switch state from s to 
q 
4. (( q, b, a), (q, e))  // continue pop a 
5. ((q,e,e),(f,e))  // go to final state 
  S
f
c , e/e 
a , a/e
b , b/e 
a , e/a
b , e/b
ioenotes.edu.np

 
State diagram 
 
 
 
 
 
 
 
e.g Lets check for the string aabb  
 
State 
Unread input 
stack content 
Transition used 
s 
aabb 
e 
- 
s 
abb 
a 
1 
s 
bb 
aa 
2 
s 
b 
a 
3 
q 
e 
e 
4 
f 
e 
e 
5 
 
 
Example 3: Design a PDA that accept the following language L = {WWR : w ∈ {a, b } * }. 
Solution: By analysis of language the machine must guess when it has reached the middle of the 
input string and change from state s to state f in a non deterministic fashion.  
 
Let required PDA,   M= (K, ∑, Г ,∆ , S , F) where  
K = {s , q, f} 
∑= {a, b} 
Г= {a, b} 
F = {f} and  
∆  is given by following five transitions 
1. ((s, a, e),(s, a) //push a 
2. ((s, b, e),(s, b) //push b 
3. ((s, e, e),(f, e))  //change the state non deterministically  (middle of the input 
string is guessed by machine M itself) 
4. (( f, a, a), (f, e))  // pop a 
5. ((f, b, b),(f, e))  // pop b  
 
Here, ((s, e, e), (f, e))   means change to state f without reading /consuming any symbol. Clearly 
whenever the M is in state S it can non- deterministically choose either to push the next input 
symbol on the stack or to switch to state f without consuming any input. 
 
 
 
 
  S
f
b , a/e 
a , e/a
a , a/a
  q
b , a/e 
e , e/e
  S
f
e , e/e 
a , a/e
b , b/e 
a , e/a
b , e/b
ioenotes.edu.np

 
 
 
Example 4: Design a PDA that accepts the language  
L= {ai bj ck  :  i,  j,  k ≥ O  and i =  j or i = k}. 
 
Solution :  
 
Let required PDA,   M= (K, ∑, Г ,∆ , S , F) where  
K = {q1 , q2, q3, q4, q5,  q6,  q7} 
∑= {a, b,c} 
Г= {a, b} 
F = {q4, q7} and 
 ∆  is given by following transition diagram  
 
Informally the PDA for this language works by first reading and pushing the a's. When 
the a's are done the machine has all of them on the stack so that it can match them with 
either the b's or the c's. This is a bit tricky because the machine doesn't know in advance 
whether to match the a's with the b's or the c's. Non-determinism comes in handy here. 
Using its non-determinism, the PDA can guess whether to match the a's with the b's or 
with the c's, as shown in the following figure. Think of the machine as having two 
branches of its non-determinism, one for each possible guess. If either of them match, 
that branch accepts and the entire machine accepts. In fact we could show, though we do 
not do so, that non-determinism is essential for recognizing this language with a PDA. 
 
 
 
ioenotes.edu.np

 
 
 
 
 
 
Deterministic PDA (DPDA) 
 
 A PDA is deterministic if there is at most one move for any input symbol, any top stack 
symbol and at any state 
 A no move or move without advancing input string are possible in a deterministic PDA 
 A move without advancing input string implies that no other move exists 
 The PDA for WCWR   is deterministic 
 The set of languages accepted by DPDA's is only a subset of language accepted by non 
deterministic PDA 
 A regular languge is language accepted by a DPDA 
 Not all language accepted by DPDA are regular 
 All languages accepted by DPDA have an unambiguous VFG 
 Not all unambiguous languages are accepted by DPDA. 
 
The PDA is deterministic in the sense that at most one move is possible from any instantaneous 
description (ID). Formally, we say that a PDA M = (Q, ∑, Г, δ, s, F), is said to be deterministic if 
it is an automation as defined in definition of PDA , subject to the restrictions that  for each q in 
Q ,   b  in T and a ϵ (∑{e} ) 
1. whenever δ (q, a, b)  contains at most one element  
2. if  δ (q, e, b)  is not  empty, then δ (q, c, b) must be  empty for every  c in ∑; 
The first of these conditions simply requires that for any given input symbol and any stack 
top ,at most one move can be made. The second condition is that when a e-transitions is 
possible for some configurations no input consuming alternative is available.   
Condition 1 prevents a choice of move for any (q, a, b) or (q, e, b). Note that unlike the 
finite automaton, a PDA is assumed to be nondeterministic unless we state otherwise. 
Condition 2 prevents the possibility of a choice between a move independent of the input 
symbol (e-move) and a move involving an input symbol.  
For finite automata, the deterministic and nondeterministic models were equivalent with respect 
to the languages accepted. The same is not true for PDA. In fact wwR is accepted by a 
nondeterministic PDA, but not by any deterministic PDA. 
 
 
 
 
 
ioenotes.edu.np

The Languages of a PDA 
We have assumed that a PDA accepts its input by consuming it and entering an accepting state. 
We call this approach acceptance by final state. We may also define for any PDA the language 
accepted by empty stack, that is, the set of  strings that cause the PDA to empty it stack, starting 
from the initial ID. 
These two methods are equivalent, in the sense that a language L has a PDA that accepts it by 
final state if and only if L has a PDA that accepts it by empty stack. 
However for a given PDA P, the languages that P accepts by final state and by empty stack are 
usually different. We will show conversion of a PDA accepting L by final state into another PDA 
that accepts L by empty stack, and vice-versa. 
Acceptance by Final State 
 
Let M = (K,, δ, s, Г,  F) be a PDA. Then Lf(M), the language accepted by M by final state, is 
 Lf(P) = { w  є * :  (s, w, e)  
 (f, e, α)  )} for some state f  є  F and any stack string α  
That is, starting in the initial ID with w waiting on the input, M consumes w from the input and 
enters an accepting state. The content of the stack at that time is irrelevant. 
 
Acceptance by Empty Stack 
Let  M = (K,, δ, s, Г,  F)  be a PDA. Then Le (M), the language accepted by M by empty stack  , 
is 
Le (M)= {w  є * :  (s, w, e) 
 (q, e, e)  )} for some state q  є K 
That is, the set of input  w that M  can consumes and at the same time empty its stack. w from 
the input and enters an accepting state. The content of the stack at that time is irrelevant. 
 
Two methods are equivalent in the sense that a language L has a PDA that accepts it by final 
state if and only if L has a PDA that accepts it by empty stack. 
 
 From Empty Stack PDA  to Final State PDA 
 From Final state PDA to Empty stack PDA  
Proof Read yourself 
 
 
 
 
 
 
 
ioenotes.edu.np

 
 
Equivalence of  PDA and CFG 
 
Theorem: The class of languages accepted by PDA is exactly the class of context free languages.  
 
Lemma1: Each CFL is accepted by some PDA. 
Lemma2: If a language is accepted by a PDA , it is a CFL. 
 
Proof of Lemma 1:  
 
Construction of PDA equivalent to a CFG.  
 
Let  G= (V, ∑, R, S) be a CFG, we must construct a PDA M such that L(M) = L(G) . The 
machine we construct has only two states p and q and remains permanently in state q after its 
first move. Also M uses V : set of terminals and ∑ set of non terminals as its stack alphabet.  
Let  M= (K, ∑, Г ,∆ , S , F) where  
K = {p, q} 
∑= ∑ 
Г= V  ∑  
S=p and    
∆ ( transition relation) is defined as  
1. ((p, e ,e), (q, S))   as S is starting non terminals of CFG. 
2. ((q, e, A), (q, x)) for each rule A x 
3. ((q, a, a) ,(q, e) ) for each a ∈ ∑ 
 
 
Example 
Consider the grammar G = (V, ∑, R, S) with V = {S, a, b ,c},  ∑ = {a, b, c}, and R = {S  aSa, 
S  bSb, S  e), which generates the language {WcWR : w є {a, b}*}.  
Design a pushdown automaton. 
Solution 
The corresponding pushdown automaton, according to the construction above, is   
M = (Q, ∑ , Г, ∆, S, F ) where  
Q= {p, q} 
∑ =∑ = {a, b, c } 
Г ={S, a, b ,c} 
S= p 
F={ q}   and  
∆= {((p, e, e), (q, S)),   
T1 
((q, e, S), (q, aSa)),  
 
T2 
((q, e, S), (q, bSb)),   
T3 
((q, e, S), (q, e)),  
 
T4 
((q, a, a), (q, e)), 
 
T5 
((q, b, b), (q, e)), 
 
T6 
((q, c, c), (q, e))} 
 
T7 
ioenotes.edu.np

 
The string abbcbba is accepted by M through the following sequence of moves. 
 
 State Unread input 
stack content 
Transition used 
p  
abbcbba 
e 
- 
q  
abbcbba 
S 
T1 
q  
abbcbba 
aSa 
T2 
q  
bbcbba 
Sa 
T5 
q 
bbcbba 
bSba 
T3 
q  
bcbba 
Sba 
T6 
q  
bcbba 
bSbba 
T3 
q  
cbba 
Sbba 
T6 
q 
cbba 
cbba 
T4 
q 
bba 
bba 
T7 
q 
ba 
ba 
T6 
q 
a 
a 
T6 
q 
e 
e 
T5 
 
 
 
 
 
 
 
 
Closure Properties of CFL 
 
Theorem 1 : The context-free languages are closed under union, concatenation, and Kleene star. 
 
Let G1=(V1, ∑1,  R1,S1)  and G2=(V2, ∑2,  R2,S2 ) be two context-free grammars, and without loss 
of generality assume that they have disjoint sets of non-terminals , that is, V1, -  ∑1   and V2 - ∑2   
are disjoint. 
 
Union:  
Let S be a new symbol and let  G= =(V, ∑,  R, S)   where  
V= V1    V2  S 
∑= ∑1   ∑2 
 
ioenotes.edu.np

R= RI U R2   {S  S1 ,   S  S2}. 
 
Then we claim that L(G) = L(G1)     L(G2) For the only rules involving S are S  S1 and S 
S2,  
so S  * G    w   if and only if either S1  * G    w  or  S2  * G    w  and since G1 and G2 have 
disjoint sets of non-terminals, the last disjunction is equivalent to saying that w є L(G1)   L(G2 
).    
 
\ 
Concatenation 
 
The construction is similar: L(G1) .L(G2)  is generated by the grammar G =(V, ∑,  R, S)    where  
V= V1    V2  S 
∑= ∑1   ∑2 
R= RI U R2   {S  S1 S2}. 
 
 
 
 
Kleene Star. 
 
L(G1)* is generated by G= =(V, ∑,  R, S)   where  
V= V1   S 
∑= ∑1  
 
R= RI U {S  e ,   S  SS2}. 
 
Theorem 2: The class of context-free languages is not closed under intersection or 
complementation. 
 
ioenotes.edu.np

This is not very surprising: Recall that our proof that regular languages are closed under 
intersection depended on closure under complementation; and that construction required that the 
automaton be deterministic. And not all context-free languages are accepted by deterministic 
pushdown automata (e.g WWR   is context free language but not accepted by Deterministic PDA 
but can be accepted by non deterministic PDA) 
 
Theorem: The intersection of a context-free language with a regular language is a context-free 
language. 
 
Proof: If L is a context-free language and R is a regular language, then L = L(M1) for some 
pushdown automaton Ml = (K1 ,, Г , ∆, S1, F1 ), and R = L(M2) for some deterministic finite 
automaton M2 = (K2, , δ, S2, F2)  The idea is to combine these machines into a single pushdown 
automaton M that carries out computations by Ml and M2 in parallel and accepts only if both 
would have accepted. Specifically, let M = (K, , Г, ∆, s, F), where 
 
K = Kl x K2, the Cartesian product of the state sets of Ml and M2; 
f = f 1 ; 
s = (Sl, S2); 
F = Fl X F2, and 
∆, the transition relation, is defined as follows.  
For each transition of the pushdown automaton ((ql, α,, β), (pl, γ))  є  ∆, and for each state q2 є 
K2, we add to ∆. the transition (( (ql, q2), α, β), ((p1, δ( q2, a)), γ)); and for each transition of the 
form (( ql, e, β, (p1 , γ )) є  ∆ and each state q2 є  K2, we add to ∆  the transition (( (ql , q2), e, β), 
((p1 , q2), γ))  That is, M passes from state (ql, q2) to state (pl, p2) in the same way that Ml passes 
from state ql to p1, except that in addition M keeps track of the change in the state of 
M2 caused by reading the same input. 
 
 
 
Regular Grammars 
A Context free grammar G = (V, ∑, R, S)  is said to be regular if each production has a right 
hand side that consists of a string of terminals followed by at most one non terminal.  
 
 A grammar is regular if it is either left- or right-linear. 
 A linear grammar may have a mix of left and right productions.  Its only restriction is that 
there is at most one symbol on the right. 
 All regular grammars are linear, but not all linear grammars are regular! 
 
Example 1: 
Let G = (V, ∑, R, S)   where  
V= { A,B,S, a,b} 
∑= { a, b} 
 
R= 
{  
S  abA/B/baB/e 
A  bS 
ioenotes.edu.np

B sS/b  
} 
 
 
Right Linear Grammars 
Right-linear: at most one variable on the right side of the production must be the right-most 
symbol. 
A  xB 
A  x 
x is any string of terminals. 
Right Regular Grammars: 
Rules of the forms 
 
A → ε 
 
A → a 
 
A → aB 
 
A, B: variables (Non terminals) and 
a: terminal 
 
Left Linear Grammars 
Left-linear: at most one variable on the right side of the production, must be the left-most 
symbol. 
 
A  Bx 
A  x 
x is any string of terminals. 
 
Left Regular Grammars: 
Rules of the forms 
 
A → ε 
 
A → a 
 
A → Ba 
 
A, B: variables (Non terminals) and 
a: terminal 
 
Prove: All right-linear grammars describe regular languages 
 Idea: Find a way to convert any right-linear grammar into a FSA. 
o Terminals before a non-terminal represent arcs 
o Non-terminals represent non-final states. 
o Terminals without non-terminals following represent final states. 
 
Regular Grammar to NFA 
Example: For the production rules of Regular  Grammar  given below  find the NFA.  
S  aD  
D  abS  
ioenotes.edu.np

D  b 
Step 1: Start variable is the initial node. 
 
Step 2: Each rule ending in a non-terminal is a chain of arcs followed by a non-final node. 
 
 
 
 
Step 3: Each rule ending in a terminal leads to a final state. 
 
 
 
Example : Transform the following Right Regular grammar in an equivalent NFAε. 
S → aS |bA  
A → cA | ε 
Solution:  
 
 
Transform the following DFA to a right regular grammar 
 
Solutions 
ioenotes.edu.np

 
 
Simplification of CFG 
 
1. Elimination of useless symbols  
 
2. Elimination of empty production (e-productions) 
3. Elimination of unit Productions  
ioenotes.edu.np
