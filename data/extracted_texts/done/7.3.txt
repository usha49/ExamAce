Introduction to Data Models, Normalization, and SQL
Data models define how data is structured, stored, and manipulated within a database system.
They serve as a blueprint for organizing and representing data efficiently. Different types of data
models are used in database management systems, each providing a unique way of handling
data relationships and constraints. The most common data models include the hierarchical
model, the network model, the relational model, and the object-oriented model. Among these,
the relational model is the most widely used in modern databases, as it provides a structured
and efficient way to store and retrieve data using tables, relationships, and constraints.
Data abstraction is the process of hiding the complexity of data storage and representation
while providing a simplified view to the user. It is categorized into three levels: physical level,
logical level, and view level. The physical level describes how data is actually stored in the
database, including indexing and file structures. The logical level defines the structure of the
entire database using tables and relationships, without specifying how the data is physically
stored. The view level provides different perspectives of the data, allowing users to access only
the relevant information without exposing the entire database.
Data independence refers to the ability to modify the database schema at one level without
affecting the higher levels. It is classified into logical data independence and physical data
independence. Logical data independence ensures that changes made to the conceptual
schema do not affect the external schema or application programs. Physical data independence
ensures that changes to the internal schema, such as indexing and storage structures, do not
impact the logical schema.
A database schema represents the structure of a database, defining tables, attributes, and
relationships. It remains fixed for a given database, providing a logical framework for organizing
data. An instance, on the other hand, refers to the actual data stored in the database at a
specific moment in time. While the schema defines the blueprint, instances are the real-time
records that exist within the database tables.
The Entity-Relationship (E-R) Model is a conceptual framework used to design and represent
database structures visually. It consists of entities, attributes, and relationships. Entities
represent real-world objects or concepts, such as students, employees, or products. They are
classified into strong entities, which have a primary key to uniquely identify each record, and

weak entities, which do not have a unique identifier and rely on a strong entity for identification.
Attributes define the characteristics of an entity, and they can be simple, composite, derived, or
multivalued. Keys are attributes or sets of attributes used to uniquely identify records within a
table. The E-R diagram is a graphical representation of entities and their relationships, helping
database designers create an efficient database structure.
Normalization is the process of organizing data to minimize redundancy and improve data
integrity. It involves decomposing large tables into smaller, more manageable tables while
preserving relationships. The different normal forms help achieve this goal by eliminating
anomalies. The First Normal Form (1NF) ensures that all attributes contain atomic values,
eliminating repeating groups. The Second Normal Form (2NF) eliminates partial dependencies
by ensuring that non-key attributes depend entirely on the primary key. The Third Normal Form
(3NF) removes transitive dependencies, ensuring that non-key attributes depend only on the
primary key. The Boyce-Codd Normal Form (BCNF) is a stricter version of 3NF, ensuring that
every determinant is a candidate key.
Functional dependencies define the relationship between attributes in a relation. If an attribute X
uniquely determines another attribute Y, then Y is functionally dependent on X. Functional
dependencies help in the normalization process by identifying redundant data and eliminating
anomalies. Integrity constraints are rules that maintain the accuracy and consistency of data in
a database. These include domain constraints, which specify the valid values for an attribute,
referential integrity, which ensures consistency in foreign key relationships, and entity integrity,
which ensures that primary key values are unique and not null.
Relations in a database refer to tables that store data. There are different types of relations,
including joined relations, which combine data from multiple tables using join operations, and
derived relations, which are created using SQL queries and views. SQL (Structured Query
Language) provides powerful commands for defining, manipulating, and querying data. SQL is
divided into Data Definition Language (DDL) and Data Manipulation Language (DML). DDL
commands include CREATE, ALTER, and DROP, which define and modify database structures.
DML commands include SELECT, INSERT, UPDATE, and DELETE, which manipulate data within
tables.
Views are virtual tables that provide a customized representation of data without storing it
physically. They help in security and data abstraction by restricting access to specific columns
or rows. Assertions are constraints that enforce specific conditions on data, ensuring that
records meet predefined criteria. Triggers are predefined actions that automatically execute
when specific events occur in the database, such as inserting, updating, or deleting records.

Relational algebra is a formal language used to describe database queries. It consists of
operations such as selection (σ), which filters rows based on a condition; projection (π), which
retrieves specific columns; union (∪), which combines data from two relations; intersection (∩),
which finds common records; difference (-), which retrieves records present in one relation but
not in another; and join (⨝), which combines related records from multiple tables.
Query cost estimation helps evaluate the efficiency of database queries. It involves analyzing
different query execution plans and selecting the most optimal one based on factors like disk
I/O, CPU usage, and indexing strategies. Query operations include selection, projection, join,
grouping, and sorting, which define how data is retrieved and processed. The evaluation of
expressions involves converting high-level SQL queries into efficient execution plans using
optimization techniques.
Query optimization is the process of improving query performance by selecting the best
execution strategy. It involves techniques such as indexing, query rewriting, using efficient joins,
and eliminating unnecessary computations. Query decomposition breaks complex queries into
smaller subqueries, allowing for efficient processing and retrieval of results. By applying
optimization techniques, database systems ensure faster response times and reduced resource
consumption, making queries more efficient and scalable.
