9.1 Introduction to AI and intelligent agent:
Concept of Artificial Intelligence
Artificial Intelligence (AI) refers to the simulation of human
intelligence in machines designed to think and act like humans. This
encompasses learning from experience, understanding language,
recognizing patterns, and making decisions. AI integrates various
disciplines, including computer science, mathematics, psychology,
neuroscience, and linguistics, to create systems capable of
performing tasks that typically require human intelligence.
AI Perspectives
AI can be viewed from multiple perspectives:
Strong AI: The belief that machines can possess consciousness and
genuine understanding.
Weak AI: The view that machines can simulate human cognition without
true consciousness.
Applied AI: Focuses on developing systems that perform specific tasks,
such as medical diagnosis or autonomous driving.
Cognitive AI: Aims to mimic human thought processes to understand
intelligence better.
History of AI,
1950s: The term "Artificial Intelligence" was coined in 1956 during
the Dartmouth Conference. Early research focused on problem-solving
and symbolic methods.
1960s-1970s: The rise and fall of AI enthusiasm, known as the "AI
winter," due to unmet expectations.

1980s: Expert systems became popular, utilizing rule-based
architectures.
1990s-2000s: Advancements in machine learning, data mining, and
natural language processing.
2010s-Present: The emergence of deep learning and neural networks,
leading to significant breakthroughs in image and speech recognition.
Applications of AI,
AI is utilized across various sectors:
Healthcare: Diagnostic systems, personalized treatment plans, and
predictive analytics.
Finance: Algorithmic trading, fraud detection, and customer service
chatbots.
Transportation: Autonomous vehicles, traffic management, and route
optimization.
Education: Personalized learning experiences, automated grading, and
virtual tutors.
Entertainment: Recommendation systems, content generation, and
interactive gaming.
Foundations of AI,
The development and functioning of Artificial Intelligence (AI)
systems rest on a blend of several core disciplines that together
provide the theoretical, mathematical, and computational basis for
building intelligent machines. These foundational areas have evolved
over decades and are deeply integrated into modern AI techniques.
Understanding these foundations is crucial for grasping how AI
systems operate and why they work the way they do.

1. Mathematics as the Foundation of AI
Mathematics is the backbone of AI, providing the tools necessary to
model, analyze, and solve complex problems. The primary branches of
mathematics relevant to AI are:
Linear Algebra
Linear algebra is the study of vectors, matrices, and linear
transformations, and it is fundamental in areas like machine learning
and neural networks.
Key Concepts:
Vectors and vector spaces.
Matrices, matrix operations, and determinants.
Eigenvalues and eigenvectors.
Linear transformations.
AI Applications:
Representing data in multi-dimensional spaces.
Transformations in computer vision.
Representing weights and activations in neural networks.
Calculus
Calculus, particularly differential and integral calculus, is vital
for optimizing functions, a common task in AI models.
Key Concepts:
Derivatives and gradients.
Partial derivatives for multivariable functions.
Gradient descent algorithm.
Integration for probabilistic models.
AI Applications:
Training machine learning models (e.g., backpropagation in neural
networks).
Optimization problems in reinforcement learning.
Curve fitting and cost minimization.
Probability and Statistics
Probability theory deals with uncertainty and randomness, while
statistics helps in data analysis and inference.
Key Concepts:
Random variables and probability distributions.
Bayesian inference.
Expectation, variance, and standard deviation.
Conditional probability and Bayes' Theorem.
AI Applications:
Uncertainty modeling in AI systems.
Probabilistic reasoning (e.g., Bayesian Networks).
Evaluating model performance (e.g., accuracy, precision, recall).
Set Theory and Logic

Set theory deals with collections of objects, and logic provides the
basis for reasoning.
Key Concepts:
Sets, subsets, intersections, unions.
Propositional and predicate logic.
Truth tables and inference rules.
AI Applications:
Knowledge representation and reasoning.
Automated theorem proving.
Logical inference systems.
Optimization
Optimization is the process of finding the best solution from all
feasible solutions.
Key Concepts:
Convex and non-convex optimization.
Lagrange multipliers.
Constrained and unconstrained optimization.
AI Applications:
Training machine learning models by minimizing loss functions.
Reinforcement learning for decision-making.
2. Computer Science as the Foundation of AI
Computer science provides the programming tools, data structures,
algorithms, and computational power needed to implement AI systems.
Algorithms and Data Structures
Algorithms are step-by-step procedures for solving computational
problems, while data structures organize data efficiently.
Key Concepts:
Search algorithms (e.g., depth-first search, breadth-first search).
Sorting algorithms.
Trees, graphs, and hash tables.
AI Applications:
Pathfinding algorithms in robotics.
Decision tree algorithms in machine learning.
Graph-based algorithms in social networks.
Programming Languages
Languages such as Python, C++, Java, and specific libraries like
TensorFlow and PyTorch are used to build AI applications.
Computational Complexity
Complexity theory helps understand the efficiency of algorithms.
Big O Notation describes the worst-case performance.
P vs NP Problem questions the solvability of certain problems in
polynomial time.

3. Psychology as the Foundation of AI
Psychology, particularly cognitive psychology, aims to understand
human thought processes, perception, learning, and problem-solving.
AI seeks to replicate these abilities.
Key Contributions from Psychology:
Human Cognition: Studies on how humans perceive, remember, and solve
problems inspire AI systems.
Learning Theories: Behavioral, cognitive, and constructivist theories
guide machine learning models.
Cognitive Architecture: Models like ACT-R and SOAR simulate human
cognitive processes.
AI Applications:
Developing human-like conversational agents.
Creating cognitive models for human-computer interaction.
Designing systems capable of learning from experience.
4. Neuroscience as the Foundation of AI
Neuroscience studies the structure and function of the human brain.
AI research, particularly in neural networks, draws inspiration from
the biological processes of neurons.
Key Concepts:
Neurons and synapses.
Neural firing patterns.
Brain plasticity and learning.
AI Applications:
Artificial Neural Networks (ANNs) mimic the human brain's structure.
Deep Learning uses multi-layered neural networks to recognize
patterns in large datasets.
Spiking Neural Networks (SNNs) attempt to model more biologically
accurate neural behavior.
5. Linguistics as the Foundation of AI
Linguistics is the scientific study of language. Natural language
processing (NLP), a subfield of AI, focuses on enabling machines to
understand and generate human language.
Key Concepts:
Syntax (structure of sentences).
Semantics (meaning of words and phrases).
Pragmatics (contextual meaning).
Morphology (word formation).
AI Applications:
Speech recognition systems (e.g., Siri, Google Assistant).
Machine translation (e.g., Google Translate).
Sentiment analysis in social media data.

6. Control Theory as the Foundation of AI
Control theory deals with the behavior of dynamic systems and is used
in robotics and automation.
Key Concepts:
Feedback control systems.
PID controllers (Proportional-Integral-Derivative).
Stability analysis.
AI Applications:
Autonomous vehicle navigation.
Adaptive systems in robotics.
Stability control in industrial automation.
7. Philosophy as the Foundation of AI
Philosophy underpins the ethical, logical, and epistemological
aspects of AI.
Key Philosophical Questions:
Can machines think?
What is intelligence?
How can we ensure AI systems align with human values?
AI Applications:
Developing ethical AI systems.
Addressing biases in machine learning models.
Defining AI's role in society.
Introduction of agents
An agent is an entity that perceives its environment through sensors
and acts upon it using actuators to achieve specific goals. Agents
can range from simple programs to complex systems like robots or
autonomous vehicles.
Structure of Intelligent agent,
An intelligent agent comprises:
Sensors: Devices or methods to perceive the environment (e.g.,
cameras, microphones).
Actuators: Mechanisms to act upon the environment (e.g., motors,
displays).

Architecture: The computing device or system where the agent's
processing occurs.
Agent Program: The software that implements the agent's decision-
making process.
Properties of Intelligent Agents,
Intelligent agents exhibit several key properties:
Autonomy: Operate without human intervention.
Reactivity: Respond to changes in the environment promptly.
Proactiveness: Take initiative to achieve goals.
Social Ability: Communicate and collaborate with other agents or
humans.
PEAS description of Agents,
The PEAS framework is a formal way of describing the key components
and environment in which an intelligent agent operates. It helps in
understanding and designing agents by clearly defining their goals,
sensory capabilities, actions, and operational environment. PEAS
stands for:
P
Performance Measure
E
Environment
A
Actuators
S
Sensors
Each of these components defines a crucial aspect of an agent’s
functionality.
The performance measure defines the criteria by which the success of
an agent is evaluated.
It answers the question: What is considered a good outcome for the
agent?

The performance measure should be well-defined, reflecting the
desired outcomes rather than the internal process of the agent.
It is not about how the agent achieves the goal but about how well
the goal is achieved.
Examples of Performance Measure:
Agent Performance Measure
Autonomous Car
Safety, travel time, passenger comfort, fuel
efficiency.
Vacuum Cleaner Robot
Cleanliness, battery efficiency, coverage.
Search Engine
Relevance of search results, user satisfaction.
Medical Diagnosis System
Accuracy of diagnosis, speed, patient
recovery rate.
Key Considerations for Performance Measure:
Completeness: It should consider all relevant aspects (e.g., a car
shouldn't drive fast but dangerously).
Balance: Avoid over-optimizing one criterion (e.g., a vacuum robot
cleaning the same spot repeatedly to ensure it is "clean").
Trade-offs: Often involves balancing multiple goals (e.g., speed vs.
safety).
2. Environment (E)
The environment is the context in which the agent operates. It
includes everything external to the agent that can affect its
performance.
It answers the question: What kind of world does the agent operate in?
Types of Environments:
Fully Observable vs. Partially Observable: Can the agent perceive the
complete state of the environment at any time?
Deterministic vs. Stochastic: Is the next state of the environment
completely determined by the current state and agent’s action, or is
there uncertainty?
Static vs. Dynamic: Does the environment change while the agent is
deliberating, or is it static?
Discrete vs. Continuous: Are the states and actions in the
environment finite (e.g., chess) or continuous (e.g., driving)?
Single-agent vs. Multi-agent: Does the agent operate alone or
alongside other agents?
Examples of Environments:
Agent Environment
Autonomous Car
Roads, traffic, weather, pedestrians.
Vacuum Cleaner Robot
Rooms with dirt, obstacles, furniture.
Search Engine
The internet, user queries, data sources.
Medical Diagnosis System
Patient data, symptoms, medical records.

3. Actuators (A)
Actuators are the mechanisms by which an agent affects its
environment.
It answers the question: What actions can the agent perform?
Actuators allow the agent to execute physical or virtual actions to
achieve its goals.
Examples of Actuators:
Agent Actuators
Autonomous Car
Steering, acceleration, braking, lights, horn.
Vacuum Cleaner Robot
Wheels, suction motor, brush, dustbin control.
Search Engine
Displaying search results, suggesting corrections.
Medical Diagnosis System
Displaying diagnosis, prescribing
medicine, sending alerts.
4. Sensors (S)
Sensors are the devices through which an agent perceives its
environment.
It answers the question: What inputs does the agent receive from the
environment?
Sensors enable the agent to gather data, which is processed to make
decisions.
Examples of Sensors:
Agent Sensors
Autonomous Car
Cameras, LiDAR, GPS, speedometer, accelerometer.
Vacuum Cleaner Robot
Dirt sensors, bump sensors, infrared sensors,
cameras.
Search Engine
User input, website data, query logs.
Medical Diagnosis System
Patient input, laboratory test results,
patient history.
Types of Agents:
Intelligent agents can be categorized based on their level of
complexity, internal structure, and the way they make decisions. The
type of agent determines how it perceives the environment, processes
information, and selects actions. There are four primary types of
agents, each representing increasing levels of sophistication:
Simple Reflexive,

Simple reflex agents act solely based on the current percept (input
from the environment). They ignore the history of previous percepts
and do not maintain any internal state. Their behavior is defined by
condition-action rules, also called production rules or if-then rules.
These agents are the simplest type but are limited in environments
that require memory or knowledge of past states.
Key Characteristics:
No internal model of the world.
Works best in fully observable environments.
Fails in partially observable or dynamic environments.
Efficient for straightforward, repetitive tasks.
Model Based,
Model-based reflex agents maintain an internal model of the
environment. This model tracks the current state based on past
percepts and actions. When the environment is partially observable,
the agent uses its internal model to fill in the gaps about
unobservable parts.
The model describes how the environment evolves (state transition)
and how the agent’s actions affect the environment.
Key Characteristics:
Maintains an internal state.
Uses a model of the environment to predict unobservable aspects.
Suitable for partially observable environments.
Updates the internal state continuously as it perceives and acts.
Goal Based,
Goal-based agents choose actions by considering future consequences
and select actions that achieve specific goals.
Unlike reflex agents, they evaluate the desirability of different
sequences of actions rather than reacting to individual percepts.
A goal is a desired state of the environment. The agent searches for
a sequence of actions that leads to the goal.
Key Characteristics:
Requires goal formulation (what is the desired outcome?).
Uses search and planning techniques to find a path to the goal.
Can handle more complex environments than reflex agents.
Flexible – Can adapt to new goals by recalculating the best actions.
Utility Based;

Utility-based agents extend goal-based agents by incorporating a
utility function.
While goal-based agents focus only on achieving the goal, utility-
based agents consider the quality of different goal states and the
cost of achieving them.
A utility function assigns a numerical value to each possible state,
indicating the desirability of that state.
The agent chooses the action that maximizes its expected utility.
Key Characteristics:
Evaluates multiple paths to a goal based on utility (cost, risk,
reward).
Considers trade-offs between competing goals.
Handles situations with uncertainty better than goal-based agents.
Allows for optimization (e.g., choosing the fastest, safest, or
cheapest solution).
Environment Types:
1. Deterministic Environment
Description:
The next state of the environment is completely determined by the current state and the agent’s
action.
There is no uncertainty about outcomes.
Key Characteristics:
Predictable.
Easier to design an agent.
Example: Chess, where each move has a predictable result.
2. Stochastic Environment
Description:
Actions do not guarantee specific outcomes due to randomness or uncertainty.
The same action can lead to different results.
Key Characteristics:
Uncertainty is involved.
Requires probabilistic reasoning.
Example: Self-driving car in traffic, where other drivers' behavior is unpredictable.
3. Static Environment
Description:
The environment does not change while the agent is thinking or performing an action.
Key Characteristics:
Easier to design and control.
Time is not a critical factor.
Example: Solving a crossword puzzle.
4. Dynamic Environment
Description:
The environment keeps changing while the agent is deciding or acting.
Key Characteristics:
Requires quick decision-making.
Time-sensitive.
Example: Robotics, autonomous vehicles.

5. Observable Environment (Fully Observable)
Description:
The agent can perceive the complete state of the environment at any time.
Key Characteristics:
Full knowledge.
Easier to design the agent.
Example: Chessboard is fully visible.
6. Semi-Observable / Partially Observable Environment
Description:
The agent can only perceive part of the environment, and some information is hidden.
Key Characteristics:
Requires internal memory to track unseen parts.
Decision-making is based on incomplete data.
Example: Driving in fog, where visibility is low.
7. Single-Agent Environment
Description:
Only one agent is acting, and its success does not depend on other agents.
Key Characteristics:
Easier to model.
Focused on achieving goals independently.
Example: Pathfinding robot.
8. Multi-Agent Environment
Description:
Multiple agents operate in the environment, and their actions can interfere or cooperate.
Key Characteristics:
Agents may compete or collaborate.
More complex.
Example: Football game, Stock market trading.
